setwd("C:/Users/Florent/Dropbox/Synchronised/Work_and_projects/Behavioral data science book/R scripts/Part IV Advanced tools/Chapter 12 - Introduction to mediation and moderation")
set.seed(1234)
options(scipen=10)
### Example with C-Mart data
# Store-level data
nb_stores <- 50
dat_stores <- tibble(
id = 1:nb_stores,
play_area = sample(c(0,0,0,1),nb_stores, replace = TRUE),
prop_children = rbeta(nb_stores,40,60-play_area),
avg_visitors = 1000 * rbeta(nb_stores,15+5*play_area,10)
)
#with(dat_stores,boxplot(avg_visitors~play_area))
#day-level data on individual visits
nb_days <- 20
visits_list <- lst()
k <- 1
for(j in 1:nb_days){
for(i in 1:nb_stores){
nb_visits <- round(rnorm(1,dat_stores$avg_visitors[i],10),0)
children <- as.integer((runif(nb_visits,0,1) <= dat_stores$prop_children[i]))
age <- round(runif(nb_visits,20,80))
duration <- pmax(3, rnorm(nb_visits, -21, 3) + age * rnorm(nb_visits,0.8,0.2) * (1 + children * rnorm(nb_visits, 0.2, 0.03)) +
children * (rnorm(nb_visits,30,5) +
rnorm(nb_visits,8,4) * dat_stores$play_area[i] +
rnorm(nb_visits,10,5) * dat_stores$play_area[i] * (60+80-age)/60) +
(1-children)*(rnorm(nb_visits,20,5) + rnorm(nb_visits,10,2) * dat_stores$prop_children[i] * dat_stores$play_area[i])
)
groceries_purchases <- pmax(0,
duration * rnorm(nb_visits, 2, 0.5) +
duration^2 * rnorm(nb_visits, 0.05^2, 0.01^2))
visits_list[[k]] <- tibble(
day = j,
store_id = i,
children = children,
age = age,
duration = duration,
play_area = dat_stores$play_area[i],
prop_children = dat_stores$prop_children[i],
groceries_purchases = groceries_purchases
)
k <- k + 1
}
}
visits = bind_rows(visits_list)
summary(visits)
ggplot(visits, aes(x=age, y=duration)) + geom_point(alpha = 0.5) +
geom_smooth(method = lm, fullrange = TRUE) + xlim(c(0,85))
summary(lm(duration~children*age*play_area, data=visits))
write_csv(visits, "chap12-data.csv")
##### Setup #####
library(Rlab)
library(tidyverse)
setwd("C:\Users\Florent\Dropbox\Synchronised\Work_and_projects\Behavioral data science book\R scripts\Part IV Advanced tools\Chapter 12 - Introduction to moderation")
set.seed(1234)
options(scipen=10)
### Example with C-Mart data
# Store-level data
nb_stores <- 50
dat_stores <- tibble(
id = 1:nb_stores,
play_area = sample(c(0,0,0,1),nb_stores, replace = TRUE),
prop_children = rbeta(nb_stores,40,60-play_area),
avg_visitors = 1000 * rbeta(nb_stores,15+5*play_area,10)
)
#with(dat_stores,boxplot(avg_visitors~play_area))
#day-level data on individual visits
nb_days <- 20
visits_list <- lst()
k <- 1
for(j in 1:nb_days){
for(i in 1:nb_stores){
nb_visits <- round(rnorm(1,dat_stores$avg_visitors[i],10),0)
children <- as.integer((runif(nb_visits,0,1) <= dat_stores$prop_children[i]))
age <- round(runif(nb_visits,20,80))
duration <- pmax(3, rnorm(nb_visits, -21, 3) + age * rnorm(nb_visits,0.8,0.2) * (1 + children * rnorm(nb_visits, 0.2, 0.03)) +
children * (rnorm(nb_visits,30,5) +
rnorm(nb_visits,8,4) * dat_stores$play_area[i] +
rnorm(nb_visits,10,5) * dat_stores$play_area[i] * (60+80-age)/60) +
(1-children)*(rnorm(nb_visits,20,5) + rnorm(nb_visits,10,2) * dat_stores$prop_children[i] * dat_stores$play_area[i])
)
groceries_purchases <- pmax(0,
duration * rnorm(nb_visits, 2, 0.5) +
duration^2 * rnorm(nb_visits, 0.05^2, 0.01^2))
visits_list[[k]] <- tibble(
day = j,
store_id = i,
children = children,
age = age,
duration = duration,
play_area = dat_stores$play_area[i],
prop_children = dat_stores$prop_children[i],
groceries_purchases = groceries_purchases
)
k <- k + 1
}
}
visits = bind_rows(visits_list)
summary(visits)
ggplot(visits, aes(x=age, y=duration)) + geom_point(alpha = 0.5) +
geom_smooth(method = lm, fullrange = TRUE) + xlim(c(0,85))
summary(lm(duration~children*age*play_area, data=visits))
write_csv(visits, "chap12-data.csv")
ggplot(visits, aes(x=duration, y=groceries_purchases)) + geom_point(alpha=0.5) + geom_smooth(method=lm)
ggplot(visits %>% select(day==1), aes(x=duration, y=groceries_purchases)) + geom_point(alpha=0.5) + geom_smooth()
last_error()
rlang::last_error()
ggplot(visits %>% filter(day==1), aes(x=duration, y=groceries_purchases)) + geom_point(alpha=0.5) + geom_smooth()
summary(lm(groceries_purchases~duration+I(duration^2), data=visits))
ggplot(visits %>% filter(day==2), aes(x=duration, y=groceries_purchases)) +
geom_point(alpha=0.5) + geom_smooth() + geom_smooth(method=lm, aes(col='red'))
ggplot(visits %>% filter(day==2), aes(x=duration, y=groceries_purchases)) +
geom_point(alpha=0.5) +
geom_smooth(method=lm, formula='groceries_purchases~duration+I(duration^2)') +
geom_smooth(method=lm, aes(col='red'))
ggplot(visits %>% filter(day==2), aes(x=duration, y=groceries_purchases)) +
geom_point(alpha=0.5) +
geom_smooth(method=lm, formula='groceries_purchases~poly(duration,2)') +
geom_smooth(method=lm, aes(col='red'))
ggplot(visits %>% filter(day==2), aes(x=duration, y=groceries_purchases)) +
geom_point(alpha=0.5) +
geom_smooth(method=lm, formula='y~poly(x,2)') +
geom_smooth(method=lm, aes(col='red'))
##### Setup #####
library(Rlab)
library(tidyverse)
setwd("C:\Users\Florent\Dropbox\Synchronised\Work_and_projects\Behavioral data science book\R scripts\Part IV Advanced tools\Chapter 12 - Introduction to moderation")
set.seed(1234)
options(scipen=10)
### Example with C-Mart data
# Store-level data
nb_stores <- 50
dat_stores <- tibble(
id = 1:nb_stores,
play_area = sample(c(0,0,0,1),nb_stores, replace = TRUE),
prop_children = rbeta(nb_stores,40,60-play_area),
avg_visitors = 1000 * rbeta(nb_stores,15+5*play_area,10)
)
#with(dat_stores,boxplot(avg_visitors~play_area))
#day-level data on individual visits
nb_days <- 20
visits_list <- lst()
k <- 1
for(j in 1:nb_days){
for(i in 1:nb_stores){
nb_visits <- round(rnorm(1,dat_stores$avg_visitors[i],10),0)
children <- as.integer((runif(nb_visits,0,1) <= dat_stores$prop_children[i]))
age <- round(runif(nb_visits,20,80))
duration <- pmax(3, rnorm(nb_visits, -21, 3) + age * rnorm(nb_visits,0.8,0.2) * (1 + children * rnorm(nb_visits, 0.2, 0.03)) +
children * (rnorm(nb_visits,30,5) +
rnorm(nb_visits,8,4) * dat_stores$play_area[i] +
rnorm(nb_visits,10,5) * dat_stores$play_area[i] * (60+80-age)/60) +
(1-children)*(rnorm(nb_visits,20,5) + rnorm(nb_visits,10,2) * dat_stores$prop_children[i] * dat_stores$play_area[i])
)
groceries_purchases <- pmax(0,
duration * rnorm(nb_visits, 2, 0.5) +
duration^2 * rnorm(nb_visits, 0.06^2, 0.01^2))
visits_list[[k]] <- tibble(
day = j,
store_id = i,
children = children,
age = age,
duration = duration,
play_area = dat_stores$play_area[i],
prop_children = dat_stores$prop_children[i],
groceries_purchases = groceries_purchases
)
k <- k + 1
}
}
visits = bind_rows(visits_list)
summary(visits)
# ggplot(visits, aes(x=age, y=duration)) + geom_point(alpha = 0.5) +
#   geom_smooth(method = lm, fullrange = TRUE) + xlim(c(0,85))
summary(lm(duration~children*age*play_area, data=visits))
summary(lm(groceries_purchases~duration+I(duration^2), data=visits))
ggplot(visits %>% filter(day==2), aes(x=duration, y=groceries_purchases)) +
geom_point(alpha=0.5) +
geom_smooth(method=lm, formula='y~poly(x,2)') +
geom_smooth(method=lm, aes(col='red'))
write_csv(visits, "chap12-data.csv")
?seq
dat <- tibble(
X = 1:100,
Y = X^2,
Z = sqrt(X)
)
p1 <- ggplot(dat, aes(X,Y)) + geom_point()
p2 <- ggplot(dat, aes(X,Z)) + geom_point()
ggarrange(p1, p2, ncol=2, nrow=1)
library(ggpubr)
p1 <- ggplot(dat, aes(X,Y)) + geom_point()
p2 <- ggplot(dat, aes(X,Z)) + geom_point()
ggarrange(p1, p2, ncol=2, nrow=1)
p1 <- ggplot(dat, aes(X,Y)) + geom_point()
p2 <- ggplot(dat, aes(X,Z)) + geom_point()
ggarrange(p2, p1, ncol=2, nrow=1)
dat <- tibble(
X = 1:10,
Y = X^2,
Z = log(X)
)
p1 <- ggplot(dat, aes(X,Z)) + geom_point() + xlab("marketing emails") + ylab("purchases")
p2 <- ggplot(dat, aes(X,Y)) + geom_point() + xlab("number of properties") + ylab("number of customers")
ggarrange(p1, p2, ncol=2, nrow=1)
p1 <- ggplot(dat, aes(X,Z)) + geom_point() + xlab("marketing emails") + ylab("avg. monthly purchases")
p2 <- ggplot(dat, aes(X,Y)) + geom_point() + xlab("number of properties (1000s)") + ylab("number of customers (1000s)")
ggarrange(p1, p2, ncol=2, nrow=1)
p1 <- ggplot(dat, aes(X,Z)) + geom_point() + xlab("avg. monthly marketing emails") + ylab("avg. monthly purchases")
p2 <- ggplot(dat, aes(X,Y)) + geom_point() + xlab("number of properties (1000s)") + ylab("number of customers (1000s)")
ggarrange(p1, p2, ncol=2, nrow=1)
summary(lm(data=dat, Y~X))
summary(lm(data=dat, Y~poly(X,2)))
dat <- tibble(
X = 1:10,
Y = X^2 + rnorm(10, 0, 5),
Z = log(X) + rnorm(10, 0, 0.3)
)
p1 <- ggplot(dat, aes(X,Z)) + geom_point() + xlab("avg. monthly marketing emails") + ylab("avg. monthly purchases")
p2 <- ggplot(dat, aes(X,Y)) + geom_point() + xlab("number of properties (1000s)") + ylab("number of customers (1000s)")
ggarrange(p1, p2, ncol=2, nrow=1)
dat <- tibble(
X = 1:10,
Y = X^2 + rnorm(10, 0, 2),
Z = log(X) + rnorm(10, 0, 0.1)
)
p1 <- ggplot(dat, aes(X,Z)) + geom_point() + xlab("avg. monthly marketing emails") + ylab("avg. monthly purchases")
p2 <- ggplot(dat, aes(X,Y)) + geom_point() + xlab("number of properties (1000s)") + ylab("number of customers (1000s)")
ggarrange(p1, p2, ncol=2, nrow=1)
dat <- tibble(
X = seq(from = 1, to = 10, by = 0.5),
Y = X^2 + rnorm(20, 0, 2),
Z = log(X) + rnorm(20, 0, 0.1)
)
dat <- tibble(
X = seq(from = 1, to = 10, by = 0.5),
Y = X^2 + rnorm(19, 0, 2),
Z = log(X) + rnorm(19, 0, 0.1)
)
p1 <- ggplot(dat, aes(X,Z)) + geom_point() + xlab("avg. monthly marketing emails") + ylab("avg. monthly purchases")
p2 <- ggplot(dat, aes(X,Y)) + geom_point() + xlab("number of properties (1000s)") + ylab("number of customers (1000s)")
ggarrange(p1, p2, ncol=2, nrow=1)
summary(lm(data=dat, Y~X+I(X^2)))
summary(lm(data=dat, Z~X+I(X^2)))
mod2 <- lm(data=dat, Z~X+I(X^2))
mod2$fitted.values
ggplot(dat, aes(X,Z)) + geom_point() +
xlab("avg. monthly marketing emails") +
ylab("avg. monthly purchases") +
geom_point(aes(y=mod2$fitted.values, col='red'))
dat <- dat %>%
mutate(pred_Z_lin = lm(data=dat, Z~X)$fitted.values,
pred_Z_quad = lm(data=dat, Z~X+I(X^2))$fitted.values)
ggplot(dat, aes(X,Z)) + geom_point(alpha=0.5) +
xlab("avg. monthly marketing emails") +
ylab("avg. monthly purchases") +
geom_point(aes(y=pred_Z_lin, col='red', pch=3))
ggplot(dat, aes(X,Z)) + geom_point(alpha=0.5) +
xlab("avg. monthly marketing emails") +
ylab("avg. monthly purchases") +
geom_point(aes(y=pred_Z_lin, col='red', shape=3))
ggplot(dat, aes(X,Z)) + geom_point(alpha=0.5) +
xlab("avg. monthly marketing emails") +
ylab("avg. monthly purchases") +
geom_point(aes(y=pred_Z_lin, col='red'),  shape=3)
ggplot(dat, aes(X,Z)) + geom_point(alpha=0.3, shape=1) +
xlab("avg. monthly marketing emails") +
ylab("avg. monthly purchases") +
geom_point(aes(y=pred_Z_lin, col='red'),  shape=3) +
geom_point(aes(y=pred_Z_quad, col='blue'),  shape=15)
ggplot(dat, aes(X,Z)) + geom_point(shape=1) +
xlab("avg. monthly marketing emails") +
ylab("avg. monthly purchases") +
geom_point(aes(y=pred_Z_lin, col='red'),  shape=3) +
geom_point(aes(y=pred_Z_quad, col='blue'),  shape=15)
ggplot(dat, aes(X,Z)) + geom_point(shape=16) +
xlab("avg. monthly marketing emails") +
ylab("avg. monthly purchases") +
geom_point(aes(y=pred_Z_lin, col='red'),  shape=3) +
geom_point(aes(y=pred_Z_quad, col='blue'),  shape=15) + guides(fill=FALSE)
ggplot(dat, aes(X,Z)) + geom_point(shape=16) +
xlab("avg. monthly marketing emails") +
ylab("avg. monthly purchases") +
geom_line(aes(y=pred_Z_lin, col='red')) +
geom_line(aes(y=pred_Z_quad, col='blue')) + guides(fill=FALSE)
ggplot(dat, aes(X,Z)) + geom_point(shape=16) +
xlab("avg. monthly marketing emails") +
ylab("avg. monthly purchases") +
geom_line(aes(y=pred_Z_lin, col='red'), lty="dashed") +
geom_line(aes(y=pred_Z_quad, col='blue')) + guides(fill=FALSE)
ggplot(dat, aes(X,Z)) + geom_point(shape=16) +
xlab("avg. monthly marketing emails") +
ylab("avg. monthly purchases") +
geom_line(aes(y=pred_Z_lin, col='red'), lty="dashed", show.legend=FALSE) +
geom_line(aes(y=pred_Z_quad, col='blue'), show.legend=FALSE)
visits %>% group_by(play_area) %>% summrize(s = var(duration))
visits %>% group_by(play_area) %>% summarize(s = var(duration))
visits %>% group_by(play_area) %>% summarize(s = sd(duration))
summary(lm(duration~children*age*play_area, data=visits))
visits %>% group_by(children) %>% summarize(N=n())
visits %>% group_by(children) %>% summarize(N=n(), dur = mean(duration))
summary(visits$duration)
viz_dat <- visits %>%
dplyr::group_by(children) %>%
summarise(prop_c = n()/nrow(visits)) %>%
mutate(duration = 50.09)
viz_dat
viz_dat <- visits %>%
dplyr::group_by(children) %>%
mutate(children = factor(children)) %>%
summarise(prop = n()/nrow(visits)) %>%
mutate(duration = 50.09)
viz_dat
ggplot(viz_dat, aes(x=children, y=duration, fill=children, width=prop*1.99)) +
geom_bar(stat='identity')
ggplot(viz_dat, aes(x=children, y=duration, fill=children, width=prop*1.98)) +
geom_bar(stat='identity') + ylim(c(0,100))
visits %>% group_by(play_area) %>% summarize(mean = mean(duration),
sd = sd(duration))
viz_dat0 <- visits %>%
summarise(duration = mean(duration))
ggplot(viz_dat0, aes(y=duration, width=prop*1.98)) +
geom_bar(stat='identity') + ylim(c(0,100))
ggplot(viz_dat0, aes(y=duration, width=4)) +
geom_bar(stat='identity') + ylim(c(0,100))
ggplot(viz_dat0, aes(x=0, y=duration, width=4)) +
geom_bar(stat='identity') + ylim(c(0,100))
ggplot(viz_dat0, aes(x=0, y=duration, width=4)) +
geom_bar(stat='identity',  show.legend=FALSE) + ylim(c(0,100))
ggplot(viz_dat0, aes(x=0, y=duration, width=4)) +
geom_bar(stat='identity',  show.legend=FALSE) + ylim(c(0,100)) +
theme(axis.title.x=element_blank(),
axis.text.x = element_blank(),
axis.ticks.x = element_blank())
install.packages(c("caret", "pwr", "MBESS"))
install.packages(c("pwr", "MBESS", "caret"), lib="C:/Program Files/R/R-3.6.3/library")
install.packages("OpenMx")
install.packages("OpenMx", lib="C:/Program Files/R/R-3.6.3/library")
install.packages("pkgbuild")
install.packages("pkgbuild", lib="C:/Program Files/R/R-3.6.3/library")
rt_path = gsub("\\","/",pkgbuild::rtools_path(),fixed=T)
rt_bin = paste0(substr(rt_path,1,nchar(rt_path)-4),"/mingw_$(WIN)/bin/")
writeLines(paste0('PATH="',rt_path,';${PATH}"'), con = "~/.Renviron")
writeLines(paste0('Sys.setenv(BINPREF = "',rt_bin,'")'), con = "~/.Rprofile")
install.packages("OpenMx", lib="C:/Program Files/R/R-3.6.3/library", type="source")
Sys.getenv("BINPREF")
Sys.which("make")
install.packages("jsonlite", type = "source")
getwd()
##### Setup #####
set.seed(1235)
options(scipen=10)
library(tidyverse)
library(ggpubr) # Enabling multiplots w function ggarrange
sourceDir <- getSrcDirectory(function(dummy) {dummy})
sourceDir <- dirname(sys.frame(1)$ofile)
p <- 0.1^10
##### Setup #####
library(Rlab)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(rstudioapi)
### Setting the working directory to the parent folder of this script (Rstudio only)
sourceDir <- rstudioapi::getActiveDocumentContext()$path %>% str_extract("^.+/")
setwd(sourceDir)
options(scipen=10)
### Data generation
set.seed(1234)
times <- c(2,2,3,5,6,9,10,47,61,413)
experience <- c(11,17,18,1,10,4,6,3,8,0)
dat <- tibble(times = times,
experience = experience)
##### Intro to the Bootstrap #####
# Figure 7-1. Experience and preparation time by baker
ggplot(dat, aes(x=experience, y=times)) +
geom_point() + xlab("Months of Experience") + ylab("Baking Times (in minutes)")
# Building linear model
lin_mod_summ <- summary(lm(times~1, data=dat))
est <- lin_mod_summ$coefficients[1,1]
se <- lin_mod_summ$coefficients[1,2]
#Building normal confidence interval
LL <- est-1.96*se
UL <- est+1.96*se
#Building Bootstrap CI
mean_lst <- list()
N <- nrow(dat)
B <- 2000
for(i in 1:B){
boot_dat <- slice_sample(dat, n=N, replace = TRUE)
M <- mean(boot_dat$times)
if(M >= 200){cat(boot_dat$times, "\n")}
mean_lst[[i]] <- M
}
mean_summ <- tibble(means = unlist(mean_lst))
LL_b <- as.numeric(quantile(mean_summ$means, c(0.025)))
UL_b <- as.numeric(quantile(mean_summ$means, c(0.975)))
M_b <- mean(mean_summ$means)
# Figure 7-2. Distribution of the means of 2,000 samples
ggplot(mean_summ, aes(x=means)) + geom_histogram()
# Figure 7-3. Distribution of the means of 2,000 samples,
# with mean of the means (thick line), normal CI bounds (dotted lines) and
# bootstrap CI bounds (dashed lines).
ggplot(mean_summ, aes(x=means)) + geom_histogram() +
#geom_vline(xintercept = est, col ='red', size=2) +
geom_vline(xintercept = LL, size = 1.5, lty='dotted') +
geom_vline(xintercept = UL, size = 1.5, lty='dotted') +
geom_vline(xintercept = LL_b, size = 1.5, lty='dashed', col='blue') +
geom_vline(xintercept = UL_b, size = 1.5, lty='dashed', col='blue') +
geom_vline(xintercept = M_b,size = 2, col='blue')
# Figure 7-3. Distribution of the means of 2,000 samples,
# with mean of the means (thick line), normal CI bounds (dotted lines) and
# bootstrap CI bounds (dashed lines).
ggplot(mean_summ, aes(x=means)) + geom_histogram() +
#geom_vline(xintercept = est, col ='red', size=2) +
geom_vline(xintercept = LL, size = 1.25, lty='dotted') +
geom_vline(xintercept = UL, size = 1.25, lty='dotted') +
geom_vline(xintercept = LL_b, size = 1.25, lty='dashed', col='blue') +
geom_vline(xintercept = UL_b, size = 1.25, lty='dashed', col='blue') +
geom_vline(xintercept = M_b,size = 2, col='blue')
#### Bootstrap for time promise
promise_fun <- function(dat, B = 2000){
N <- nrow(dat)
promise_lst <- list()
for(i in 1:B){
boot_dat <- slice_sample(dat, n=N, replace = TRUE)
above180 <- sum(boot_dat$times >= 180)/nrow(boot_dat)
promise_lst[[i]] <- above180
}
promise_summ <- tibble(above180 = unlist(promise_lst))
return(promise_summ)
}
promise_summ <- promise_fun(dat, B = 2000)
# Figure 7-4. Distribution of the proportion of each sample with a preparation
# time above 180mn.
ggplot(promise_summ, aes(x=above180)) + geom_histogram() +
scale_x_continuous(breaks=seq(from=0,to=0.6,by=0.1)) +
xlab("proportion of sample with preparation time above 180mn")
2000*0.025
# Figure 7-5. Distribution of the regression coefficients of preparation time
# on experience, with their mean (thick line), bootstrap CI bounds (thick
# dashed lines) and normal CI bounds (thin dotted lines)
# (B=4,000 bootstrap samples)
ggplot(reg_summ, aes(x=coeff)) + geom_histogram(bins=500) + xlim(c(-45,5)) +
geom_vline(xintercept = M_b, col ='blue', size=2) +
geom_vline(xintercept = LL, size = 1.25, lty='dotted') +
geom_vline(xintercept = UL, size = 1.25, lty='dotted') +
geom_vline(xintercept = LL_b, size = 1.25, lty='dashed', size = 1.5, col='blue') +
geom_vline(xintercept = UL_b, size = 1.25, lty='dashed', size = 1.5, col='blue') +
xlab("regression coefficient of preparation time on experience")
#Running the baseline model
mod <- lm(times~experience, data=dat)
mod_summ <- summary(mod)
mod_summ
est <- mod_summ$coefficients[2,1]
se <- mod_summ$coefficients[2,2]
LL <- est-1.96*se
UL <- est+1.96*se
reg_fun <- function(dat, B = 2000){
N <- nrow(dat)
reg_lst <- list()
for(i in 1:B){
boot_dat <- slice_sample(dat, n=N, replace = TRUE)
summ <- summary(lm(times~experience, data=boot_dat))
coeff <- summ$coefficients['experience','Estimate']
reg_lst[[i]] <- coeff
}
reg_summ <- tibble(coeff = unlist(reg_lst))
return(reg_summ)
}
reg_summ <- reg_fun(dat, B=2000)
M_b <- mean(reg_summ$coeff)
LL_b <- as.numeric(quantile(reg_summ$coeff, c(0.025)))
UL_b <- as.numeric(quantile(reg_summ$coeff, c(0.975)))
# Figure 7-5. Distribution of the regression coefficients of preparation time
# on experience, with their mean (thick line), bootstrap CI bounds (thick
# dashed lines) and normal CI bounds (thin dotted lines)
# (B=4,000 bootstrap samples)
ggplot(reg_summ, aes(x=coeff)) + geom_histogram(bins=500) + xlim(c(-45,5)) +
geom_vline(xintercept = M_b, col ='blue', size=2) +
geom_vline(xintercept = LL, size = 1.25, lty='dotted') +
geom_vline(xintercept = UL, size = 1.25, lty='dotted') +
geom_vline(xintercept = LL_b, size = 1.25, lty='dashed', size = 1.5, col='blue') +
geom_vline(xintercept = UL_b, size = 1.25, lty='dashed', size = 1.5, col='blue') +
xlab("regression coefficient of preparation time on experience")
reg_fun <- function(dat, B = 2000){
N <- nrow(dat)
reg_lst <- list()
for(i in 1:B){
boot_dat <- slice_sample(dat, n=N, replace = TRUE)
summ <- summary(lm(times~experience, data=boot_dat))
coeff <- summ$coefficients['experience','Estimate']
reg_lst[[i]] <- coeff
}
reg_summ <- tibble(coeff = unlist(reg_lst))
return(reg_summ)
}
reg_summ <- reg_fun(dat, B=4000)
M_b <- mean(reg_summ$coeff)
LL_b <- as.numeric(quantile(reg_summ$coeff, c(0.025)))
UL_b <- as.numeric(quantile(reg_summ$coeff, c(0.975)))
# Figure 7-5. Distribution of the regression coefficients of preparation time
# on experience, with their mean (thick line), bootstrap CI bounds (thick
# dashed lines) and normal CI bounds (thin dotted lines)
# (B=4,000 bootstrap samples)
ggplot(reg_summ, aes(x=coeff)) + geom_histogram(bins=500) + xlim(c(-45,5)) +
geom_vline(xintercept = M_b, col ='blue', size=2) +
geom_vline(xintercept = LL, size = 1.25, lty='dotted') +
geom_vline(xintercept = UL, size = 1.25, lty='dotted') +
geom_vline(xintercept = LL_b, size = 1.25, lty='dashed', size = 1.5, col='blue') +
geom_vline(xintercept = UL_b, size = 1.25, lty='dashed', size = 1.5, col='blue') +
xlab("regression coefficient of preparation time on experience")
