{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decent-playback",
   "metadata": {},
   "source": [
    "# Chapter 8: Experimental design 2 - stratified randomization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-skirt",
   "metadata": {},
   "source": [
    "## Libraries and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-running",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-michigan",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Loading the data #####\n",
    "\n",
    "hist_data_df = pd.read_csv('chap8-historical_data.csv')\n",
    "exp_data_df = pd.read_csv('chap8-experimental_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-print",
   "metadata": {},
   "source": [
    "## Determining random assignment and sample size/power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-moscow",
   "metadata": {},
   "source": [
    "### Random assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for assignment completely at random with 3 experimental groups\n",
    "def no_strat_assgnt_fun(dat_df, Nexp):\n",
    "    K = 3\n",
    "    dat_df = pd.DataFrame({'ID': dat_df.ID.unique()})\n",
    "    dat_df = dat_df.sample(Nexp)\n",
    "    dat_df['assgnt'] = np.random.uniform(0,1,Nexp)\n",
    "    dat_df['group'] = 'ctrl'\n",
    "    dat_df.loc[dat_df['assgnt'].between(0, 1/K, inclusive=True), \n",
    "               'group'] = 'treat1'\n",
    "    dat_df.loc[dat_df['assgnt'].between(1/K, 2/K, inclusive=False), \n",
    "               'group'] = 'treat2'\n",
    "    del(dat_df['assgnt'])\n",
    "    return dat_df\n",
    "no_strat_assgnt = no_strat_assgnt_fun(hist_data_df, Nexp = 4998)\n",
    "\n",
    "# Extension of the previous function for any number K\n",
    "def no_strat_assgnt_K_fun(dat_df, Nexp, K):\n",
    "    dat_df = pd.DataFrame({'ID': dat_df.ID.unique()})\n",
    "    dat_df = dat_df.sample(Nexp)\n",
    "    dat_df['assgnt'] = np.random.uniform(0,1,Nexp)\n",
    "    dat_df['group'] = -1 # initializing the “group” variable\n",
    "    for i in range(K):\n",
    "        dat_df.loc[dat_df['assgnt'].between(i/K, (i+1)/K, inclusive=True), \n",
    "               'group'] = i\n",
    "    del(dat_df['assgnt'])\n",
    "    return dat_df   \n",
    "no_strat_assgnt = no_strat_assgnt_K_fun(hist_data_df, Nexp = 5000, K = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to prep the data\n",
    "def strat_prep_fun(dat_df):\n",
    "    #Extracting property-level variables\n",
    "    dat_df['tier'] = pd.Categorical(dat_df.tier, categories=[3,2,1], \n",
    "                                    ordered = True)\n",
    "    dat_df['ID'] = dat_df.ID.astype(str)\n",
    "    \n",
    "    \n",
    "    num_df = dat_df.copy().loc[:,dat_df.dtypes=='float64'] #Numeric vars \n",
    "    cat_df = dat_df.copy().loc[:,dat_df.dtypes=='category'] #Categorical vars\n",
    "\n",
    "    #Normalizing all numeric variables to [0,1]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(num_df)\n",
    "    num_np = scaler.transform(num_df)\n",
    "    \n",
    "    #One-hot encoding all categorical variables\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(cat_df)\n",
    "    cat_np = enc.transform(cat_df).toarray()\n",
    "    \n",
    "    #Binding arrays\n",
    "    data_np = np.concatenate((num_np, cat_np), axis=1)\n",
    "    del num_df, num_np, cat_df, cat_np, enc, scaler\n",
    "    return data_np\n",
    "#prepped_data_np = strat_prep_fun(hist_data_df)\n",
    "    \n",
    "def stratified_assgnt_fun(dat_df, K = 2):\n",
    "      \n",
    "    dat_ID = dat_df.ID.astype(str).tolist() # Extract ID for later join\n",
    "\n",
    "    match_len = K - 1 # Number of matches we want to find\n",
    "    match_idx = match_len - 1 # Accounting for 0-indexing\n",
    "    \n",
    "    data_np = strat_prep_fun(dat_df)\n",
    "    N = len(data_np)\n",
    "    \n",
    "    #Calculate distance matrix\n",
    "    from scipy.spatial import distance_matrix\n",
    "    d_mat = distance_matrix(data_np, data_np)\n",
    "    np.fill_diagonal(d_mat,N+1)\n",
    "    # Set up variables\n",
    "    available = [i for i in range(N)]\n",
    "    available_temp = available.copy()\n",
    "    matches_lst = []\n",
    "    lim = int(N/match_len)\n",
    "    \n",
    "    closest = np.argpartition(d_mat, kth=match_idx,axis=1)\n",
    "    \n",
    "    for n in available:\n",
    "        #print(\"n = \", n)\n",
    "        if len(matches_lst) == lim: break\n",
    "        if n in available_temp:\n",
    "            for match_lim in range(match_idx,N-1):\n",
    "                #print(\"match_lim = \", match_lim)\n",
    "                possible_matches = closest[n,:match_lim].tolist()\n",
    "                matches = list(set(available_temp) & set(possible_matches))\n",
    "                #print(\"len(matches) = \",  len(matches))\n",
    "                if len(matches) == match_len:\n",
    "                    matches.append(n)\n",
    "                    matches_lst.append(matches)\n",
    "                    available_temp = [m for m in available_temp if m not in matches]\n",
    "                    break\n",
    "                else:\n",
    "                    closest[n,:] = np.argpartition(d_mat[n,:], kth=match_lim)\n",
    "                    \n",
    "    #Assigning experimental groups to the matched sets\n",
    "    exp_grps = np.array(list(range(K))*(int(N/K))).reshape((int(N/K),K))\n",
    "    exp_grps = exp_grps.tolist()\n",
    "    for j in exp_grps: \n",
    "        np.random.shuffle(j)\n",
    "    #flattening the two lists\n",
    "    import itertools\n",
    "    exp_grps = list(itertools.chain(*exp_grps))\n",
    "    matches_lst2 = list(itertools.chain(*matches_lst))\n",
    "    exp_grps2 = [x for _,x in sorted(zip(matches_lst2,exp_grps))]\n",
    "    \n",
    "    assgnt_df = pd.DataFrame(exp_grps2, columns=['group'])\n",
    "    assgnt_df.group = assgnt_df.group.astype(str)\n",
    "    assgnt_df.group.loc[assgnt_df.group == '0'] = 'ctrl'\n",
    "    assgnt_df.group.loc[assgnt_df.group == '1'] = 'treat1'\n",
    "    assgnt_df.group.loc[assgnt_df.group == '2'] = 'treat2'\n",
    "    \n",
    "    \n",
    "    assgnt_df['ID'] = dat_ID\n",
    "    dat_df = dat_df.merge(assgnt_df, on='ID', how='inner')\n",
    "    return dat_df\n",
    "\n",
    "#Sampling a random monthly period\n",
    "per = random.sample(range(35), 1)[0] + 1\n",
    "sample_df = hist_data_df.loc[hist_data_df.period == per].sample(4998)\n",
    "stratified_data_df = stratified_assgnt_fun(sample_df, K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assgnt_comparison_fun(strat_dat_df, varnm):\n",
    "    \n",
    "    strat_dat_df = stratified_data_df.copy()\n",
    "    K = 3\n",
    "    strat_dat_df.rename(columns = {'group':'strat_group'}, inplace=True)\n",
    "    strat_dat_df['assgnt'] = np.random.uniform(0,1,len(strat_dat_df))\n",
    "    strat_dat_df['group'] = -1 # initializing the “group” variable\n",
    "    for i in range(K):\n",
    "        strat_dat_df.loc[strat_dat_df['assgnt'].between(i/K, (i+1)/K, inclusive=True), \n",
    "               'group'] = i\n",
    "    del(strat_dat_df['assgnt'])\n",
    "    strat_dat_df.rename(columns = {'group':'no_strat_group'}, inplace=True)\n",
    "    \n",
    "    strat_sd = round(float(strat_dat_df.groupby('strat_group').agg(var = (varnm, 'mean')).std()), 4)\n",
    "    print(\"the s.d. between groups for\", varnm, \"is\", strat_sd, \n",
    "          \" for stratified assignment\\n\")\n",
    "    no_strat_sd = round(float(strat_dat_df.groupby('no_strat_group').agg(var = (varnm, 'mean')).std()),4)\n",
    "    print(\"the s.d. between groups for\", varnm, \"is\", no_strat_sd, \n",
    "          \"for non-stratified assignment\\n\") \n",
    "\n",
    "assgnt_comparison_fun(stratified_data_df, 'avg_review')\n",
    "assgnt_comparison_fun(stratified_data_df, 'sq_ft')\n",
    "assgnt_comparison_fun(stratified_data_df, 'BPday')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-pride",
   "metadata": {},
   "source": [
    "### Power analysis with Bootstrap simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric function for free cleaning (treatment 1)\n",
    "def treat1_metric_fun(dat_df):\n",
    "    model = ols(\"BPday~sq_ft+tier+avg_review+group\", data=dat_df)\n",
    "    res = model.fit(disp=0)\n",
    "    coeff = res.params['group[T.treat1]']\n",
    "    return coeff\n",
    "    \n",
    "# Metric function for minimum booking duration (treatment 2)\n",
    "def treat2_metric_fun(dat_df):\n",
    "    model = ols(\"BPday~sq_ft+tier+avg_review+group\", data=dat_df)\n",
    "    res = model.fit(disp=0)\n",
    "    coeff = res.params['group[T.treat2]']\n",
    "    return coeff\n",
    "\n",
    "def boot_CI_fun(dat_df, metric_fun, B = 100, conf_level = 0.9):\n",
    "  #Setting sample size\n",
    "  N = len(dat_df)\n",
    "  coeffs = []\n",
    "  \n",
    "  for i in range(B):\n",
    "      sim_data_df = dat_df.sample(n=N, replace = True)\n",
    "      coeff = metric_fun(sim_data_df)\n",
    "      coeffs.append(coeff)\n",
    "  \n",
    "  coeffs.sort()\n",
    "  start_idx = round(B * (1 - conf_level) / 2)\n",
    "  end_idx = - round(B * (1 - conf_level) / 2)\n",
    "  \n",
    "  confint = [coeffs[start_idx], coeffs[end_idx]]  \n",
    "  \n",
    "  return(confint)\n",
    "\n",
    "def decision_fun(dat_df, metric_fun, B = 100, conf_level = 0.9):\n",
    "    boot_CI = boot_CI_fun(dat_df, metric_fun, B = B, conf_level = conf_level)\n",
    "    decision = 1 if boot_CI[0] > 0  else 0\n",
    "    return decision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for single experiment\n",
    "\n",
    "def single_sim_fun(dat_df, metric_fun, Nexp, eff_size, B = 100, \n",
    "                   conf_level = 0.9):\n",
    "    \n",
    "    #Filter the data down to a random month\n",
    "    per = random.sample(range(35), 1)[0] + 1\n",
    "    dat_df = dat_df.loc[dat_df.period == per]\n",
    "    dat_df = dat_df.sample(n=Nexp)\n",
    "    \n",
    "    #Prepare the stratified assignment for a random sample of desired size \n",
    "    sample_df = dat_df.sample(Nexp)\n",
    "    sim_data_df = stratified_assgnt_fun(sample_df, K = 3)\n",
    "    \n",
    "    #Add target effect size\n",
    "    sim_data_df.BPday = np.where(sim_data_df.group == 'treat2', \n",
    "                                 sim_data_df.BPday + eff_size, sim_data_df.BPday)\n",
    "    \n",
    "    #Calculate the decision (we want it to be 1)\n",
    "    decision = decision_fun(sim_data_df, metric_fun, B = B, \n",
    "                            conf_level = conf_level)\n",
    "    return decision\n",
    "    \n",
    "single_sim_fun(hist_data_df, treat2_metric_fun, Nexp=99, eff_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for simulations at scale\n",
    "#Standard function\n",
    "def power_sim_fun(dat_df, metric_fun, Nexp, eff_size, Nsim, B = 100, \n",
    "                  conf_level = 0.9):\n",
    "    power_lst = []\n",
    "    for i in range(Nsim):\n",
    "        power_lst.append(single_sim_fun(dat_df, metric_fun = metric_fun, \n",
    "                                        Nexp = Nexp, eff_size = eff_size, \n",
    "                                        B = B, conf_level = conf_level))\n",
    "    power = np.mean(power_lst)\n",
    "    return(power)  \n",
    "power = power_sim_fun(hist_data_df, treat2_metric_fun, Nexp = 1500, eff_size = 2, \n",
    "                      Nsim = 100, B = 100, conf_level = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-carter",
   "metadata": {},
   "source": [
    "## Analyzing and interpreting experimental results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restating tier as a factor variable\n",
    "exp_data_df['tier'] = pd.Categorical(exp_data_df.tier, \n",
    "                                      categories=[3,2,1], \n",
    "                                      ordered = True)\n",
    "\n",
    "#Linear regression\n",
    "exp_data_reg_df = exp_data_df.copy()\n",
    "exp_data_reg_df.BPday = np.where((exp_data_reg_df.compliant == 1) & \\\n",
    "                                 (exp_data_reg_df.group == 'treat2'), \n",
    "                                 exp_data_reg_df.BPday -10, \n",
    "                                 exp_data_reg_df.BPday) \n",
    "print(ols(\"BPday~sq_ft+tier+avg_review+group\", \n",
    "          data=exp_data_reg_df).fit(disp=0).summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_CI_fun(exp_data_reg_df, treat1_metric_fun)\n",
    "boot_CI_fun(exp_data_reg_df, treat2_metric_fun)\n",
    "\n",
    "#T-test of means for treatment 1\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "test = ttest_ind(exp_data_df[exp_data_df.group == 'ctrl']['BPday'], \n",
    "                 exp_data_df[exp_data_df.group == 'treat1']['BPday'], \n",
    "                 alternative = 'smaller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measurinng the compliance rate\n",
    "exp_data_reg_df.groupby('group').agg(compliance_rate = ('compliant', 'mean'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
