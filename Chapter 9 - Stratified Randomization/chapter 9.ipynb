{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "\n",
    "# Chapter-specific packages\n",
    "import random # For functions sample() and shuffle()\n",
    "# To rescale numeric variables\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# To one-hot encode cat. variables\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>period</th>\n",
       "      <th>month</th>\n",
       "      <th>sq_ft</th>\n",
       "      <th>tier</th>\n",
       "      <th>avg_review</th>\n",
       "      <th>BPday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>821.675486</td>\n",
       "      <td>2</td>\n",
       "      <td>9.393427</td>\n",
       "      <td>31.388994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>745.750743</td>\n",
       "      <td>3</td>\n",
       "      <td>7.392167</td>\n",
       "      <td>47.832222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>889.114465</td>\n",
       "      <td>3</td>\n",
       "      <td>5.623003</td>\n",
       "      <td>51.075101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>859.598058</td>\n",
       "      <td>3</td>\n",
       "      <td>6.214651</td>\n",
       "      <td>23.721855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>963.561800</td>\n",
       "      <td>3</td>\n",
       "      <td>8.096271</td>\n",
       "      <td>21.679488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID  period  month       sq_ft tier  avg_review      BPday\n",
       "0  1       1      2  821.675486    2    9.393427  31.388994\n",
       "1  2       1      2  745.750743    3    7.392167  47.832222\n",
       "2  3       1      2  889.114465    3    5.623003  51.075101\n",
       "3  4       1      2  859.598058    3    6.214651  23.721855\n",
       "4  5       1      2  963.561800    3    8.096271  21.679488"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##### Loading the data #####\n",
    "hist_data_df = pd.read_csv('chap9-historical_data.csv')\n",
    "exp_data_df = pd.read_csv('chap9-experimental_data.csv')\n",
    "\n",
    "### Minor data formatting\n",
    "\n",
    "# Reformating categorical and id variables\n",
    "hist_data_df['tier'] = pd.Categorical(hist_data_df.tier, categories=[3,2,1], ordered = True)\n",
    "hist_data_df['ID'] = hist_data_df.ID.astype(str)\n",
    "exp_data_df['tier'] = pd.Categorical(exp_data_df.tier, categories=[3,2,1], ordered = True)\n",
    "exp_data_df['ID'] = exp_data_df.ID.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>2083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>3819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>3018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>707</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>3357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>3100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>630</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1528</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>1073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>1314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  grp\n",
       "2082  2083    0\n",
       "3818  3819    0\n",
       "3017  3018    3\n",
       "706    707    3\n",
       "3356  3357    0\n",
       "...    ...  ...\n",
       "3099  3100    0\n",
       "629    630    2\n",
       "1527  1528    0\n",
       "1072  1073    0\n",
       "1313  1314    2\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def no_strat_assgnt(df, Nexp, k):\n",
    "    temp = pd.DataFrame({'ID': df.ID.unique()})\n",
    "    temp = temp.sample(Nexp)\n",
    "    grp = list(range(k)) * int(Nexp / k)\n",
    "    random.shuffle(grp)\n",
    "    temp['grp'] = grp\n",
    "    return temp\n",
    "\n",
    "no_strat_assgnt(hist_data_df, 2000, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175000 entries, 0 to 174999\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype   \n",
      "---  ------      --------------   -----   \n",
      " 0   ID          175000 non-null  object  \n",
      " 1   period      175000 non-null  int64   \n",
      " 2   month       175000 non-null  int64   \n",
      " 3   sq_ft       175000 non-null  float64 \n",
      " 4   tier        175000 non-null  category\n",
      " 5   avg_review  175000 non-null  float64 \n",
      " 6   BPday       175000 non-null  float64 \n",
      "dtypes: category(1), float64(3), int64(2), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "hist_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[821.67548629,   9.39342726,  45.93411704,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [977.68632137,  10.        ,  47.02031206,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [772.24643725,   5.05391337,  36.03493243,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       ...,\n",
       "       [931.23973925,   7.82448952,  42.00859311,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [792.20446113,   4.60368051,  32.83121812,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [859.06503328,   7.91434225,  42.09540755,   0.        ,\n",
       "          0.        ,   1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strat_prep_fun(df):\n",
    "    temp = df.copy()\n",
    "\n",
    "    temp = temp.groupby(['ID','tier'], observed=False).agg(\n",
    "        sq_ft = ('sq_ft','mean'),\n",
    "        avg_review = ('avg_review','mean'),\n",
    "        BPday = ('BPday','mean')\n",
    "    )\n",
    "    temp = temp.dropna().reset_index()\n",
    "\n",
    "    num_df = temp.copy().select_dtypes('float64')\n",
    "    cat_df = temp.copy().select_dtypes('category')\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(num_df)\n",
    "    num_np = scaler.transform(num_df)\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(cat_df)\n",
    "    cat_np = enc.transform(cat_df).toarray()\n",
    "\n",
    "    data_np = np.concatenate((num_df, cat_np), axis=1)\n",
    "    del num_df, num_np, cat_df, enc, scaler\n",
    "    return data_np\n",
    "\n",
    "prepared = strat_prep_fun(hist_data_df)\n",
    "\n",
    "prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_assgnt_fun(dat_df, K):\n",
    "    \n",
    "    #Sampling down to a multiple of our number of groups\n",
    "    remainder = len(dat_df) % K\n",
    "    if remainder != 0:\n",
    "        dat_df = dat_df.sample(len(dat_df) - remainder)\n",
    "      \n",
    "    dat_ID = dat_df.ID.astype(str).tolist() # Extract ID for later join\n",
    "\n",
    "    match_len = K - 1 # Number of matches we want to find\n",
    "    match_idx = match_len - 1 # Accounting for 0-indexing\n",
    "    \n",
    "    data_np = strat_prep_fun(dat_df)\n",
    "    N = len(data_np)\n",
    "    \n",
    "    #Calculate distance matrix\n",
    "    from scipy.spatial import distance_matrix\n",
    "    d_mat = distance_matrix(data_np, data_np)\n",
    "    np.fill_diagonal(d_mat,N+1)\n",
    "    # Set up variables\n",
    "    available = [i for i in range(N)]\n",
    "    available_temp = available.copy()\n",
    "    matches_lst = []\n",
    "    lim = int(N/match_len)\n",
    "    \n",
    "    closest = np.argpartition(d_mat, kth=match_idx,axis=1)\n",
    "    \n",
    "    for n in available:\n",
    "        #print(\"n = \", n)\n",
    "        if len(matches_lst) == lim: break\n",
    "        if n in available_temp:\n",
    "            for match_lim in range(match_idx,N-1):\n",
    "                #print(\"match_lim = \", match_lim)\n",
    "                possible_matches = closest[n,:match_lim].tolist()\n",
    "                matches = list(set(available_temp) & set(possible_matches))\n",
    "                #print(\"len(matches) = \",  len(matches))\n",
    "                if len(matches) == match_len:\n",
    "                    matches.append(n)\n",
    "                    matches_lst.append(matches)\n",
    "                    available_temp = [m for m in available_temp if m not in matches]\n",
    "                    break\n",
    "                else:\n",
    "                    closest[n,:] = np.argpartition(d_mat[n,:], kth=match_lim)\n",
    "                    \n",
    "    #Assigning experimental groups to the matched sets\n",
    "    exp_grps = np.array(list(range(K))*(int(N/K))).reshape((int(N/K),K))\n",
    "    exp_grps = exp_grps.tolist()\n",
    "    for j in exp_grps: \n",
    "        np.random.shuffle(j)\n",
    "    #flattening the two lists\n",
    "    import itertools\n",
    "    exp_grps = list(itertools.chain(*exp_grps))\n",
    "    matches_lst2 = list(itertools.chain(*matches_lst))\n",
    "    exp_grps2 = [x for _,x in sorted(zip(matches_lst2,exp_grps))]\n",
    "    \n",
    "    assgnt_df = pd.DataFrame(exp_grps2, columns=['grp'])\n",
    "    assgnt_df.grp = assgnt_df.grp.astype(str)\n",
    "    assgnt_df.grp.loc[assgnt_df.grp == '0'] = 'ctrl'\n",
    "    assgnt_df.grp.loc[assgnt_df.grp == '1'] = 'treat1'\n",
    "    assgnt_df.grp.loc[assgnt_df.grp == '2'] = 'treat2'\n",
    "    \n",
    "    \n",
    "    assgnt_df['ID'] = dat_ID\n",
    "    dat_df = dat_df.merge(assgnt_df, on='ID', how='inner')\n",
    "    return dat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric function for minimum-duration\n",
    "def treat2_metric_fun(df):\n",
    "    model = ols(\"BPday~sq_ft+tier+avg_review+grp\", data=df)\n",
    "    res = model.fit(disp=0)\n",
    "    coeff = res.params['grp[T.treat2]']\n",
    "    return coeff\n",
    "\n",
    "# determining the bootstrap sample CI \n",
    "def boot_CI_fun(df, metric_fun, B=100, conf_level = 0.9):\n",
    "    # set sample size\n",
    "    N = len(df)\n",
    "    coeffs = []\n",
    "\n",
    "    for i in range(B):\n",
    "        sim_df =  df.sample(n=N, replace=True)\n",
    "        coeff = metric_fun(sim_df)\n",
    "        coeffs.append(coeff)\n",
    "    \n",
    "    coeffs.sort()\n",
    "    start_idx = round(B * (1 -conf_level) / 2)\n",
    "    end_idx = - round(B * (1 - conf_level) / 2)\n",
    "    confint = [coeffs[start_idx], coeffs[end_idx]]\n",
    "    return confint\n",
    "\n",
    "# decision function\n",
    "def decision_fun(df, metric_fun, B = 100, conf_level = 0.9):\n",
    "    boot_CI = boot_CI_fun(df, metric_fun, B = B, conf_level=conf_level)\n",
    "    decision = 1 if boot_CI[0] > 0 else 0\n",
    "    return decision\n",
    "\n",
    "def single_sim_fun(df, metric_fun, Nexp, eff_size, B = 100, conf_level = 0.9):\n",
    "\n",
    "    # filter data to a ranodm month\n",
    "    per = random.sample(range(35), 1)[0] + 1\n",
    "    df = df.loc[df.period == per]\n",
    "    df = df.sample(n=Nexp)\n",
    "\n",
    "    # prepare stratified assignemnt for a random sample of desired size\n",
    "    sample_df = df.sample(Nexp)\n",
    "    sim_df = stratified_assgnt_fun(sample_df, K = 3)\n",
    "\n",
    "    # add target effect size\n",
    "    sim_df.BPday = np.where(\n",
    "        sim_df.grp == 'treat2',\n",
    "        sim_df.BPday + eff_size, \n",
    "        sim_df.BPday\n",
    "    )\n",
    "\n",
    "    # calculate decision (should be 1 for true effect)\n",
    "    decision = decision_fun(\n",
    "        sim_df,\n",
    "        metric_fun, \n",
    "        B = B,\n",
    "        conf_level=conf_level\n",
    "        )\n",
    "\n",
    "    return decision\n",
    "\n",
    "def power_sim_fun(df, metric_fun, Nexp, eff_size, Nsim, B = 100, conf_level = 0.9):\n",
    "    power_list = []\n",
    "    for i in range(Nsim):\n",
    "        power_list.append(\n",
    "            single_sim_fun(\n",
    "                df,\n",
    "                metric_fun=metric_fun,\n",
    "                Nexp=Nexp, \n",
    "                eff_size = eff_size,\n",
    "                B = B, \n",
    "                conf_level= conf_level\n",
    "                )\n",
    "            )\n",
    "    power = np.mean(power_list)\n",
    "    return power\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power = power_sim_fun(hist_data_df, treat2_metric_fun, Nexp = 1500, eff_size = 2, \n",
    "                      Nsim = 100, B = 100, conf_level = 0.9)\n",
    "\n",
    "power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data_reg_df = exp_data_df.copy()\n",
    "exp_data_reg_df.BPday = np.where(\n",
    "    (exp_data_reg_df.compliant == 1) & (exp_data_reg_df.grp == 'treat2'),\n",
    "    exp_data_reg_df.BPday -10,\n",
    "    exp_data_reg_df.BPday\n",
    ")\n",
    "\n",
    "ols(\"BPday~sq_ft+tier+avg_review+grp\", data=exp_data_reg_df).fit(disp=0).summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
