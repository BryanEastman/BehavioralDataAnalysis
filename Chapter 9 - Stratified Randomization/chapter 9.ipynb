{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "\n",
    "# Chapter-specific packages\n",
    "import random # For functions sample() and shuffle()\n",
    "# To rescale numeric variables\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# To one-hot encode cat. variables\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### Loading the data #####\n",
    "hist_data_df = pd.read_csv('chap9-historical_data.csv')\n",
    "exp_data_df = pd.read_csv('chap9-experimental_data.csv')\n",
    "\n",
    "### Minor data formatting\n",
    "\n",
    "# Reformating categorical and id variables\n",
    "hist_data_df['tier'] = pd.Categorical(hist_data_df.tier, categories=[3,2,1], ordered = True)\n",
    "hist_data_df['ID'] = hist_data_df.ID.astype(str)\n",
    "exp_data_df['tier'] = pd.Categorical(exp_data_df.tier, categories=[3,2,1], ordered = True)\n",
    "exp_data_df['ID'] = exp_data_df.ID.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>1835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>761</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>2641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>4960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>4432</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>1179</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>2783</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  grp\n",
       "1834  1835    3\n",
       "760    761    2\n",
       "200    201    1\n",
       "2640  2641    1\n",
       "4959  4960    1\n",
       "...    ...  ...\n",
       "5        6    2\n",
       "74      75    2\n",
       "4431  4432    1\n",
       "1178  1179    2\n",
       "2782  2783    3\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def no_strat_assgnt(df, Nexp, k):\n",
    "    temp = pd.DataFrame({'ID': df.ID.unique()})\n",
    "    temp = temp.sample(Nexp)\n",
    "    grp = list(range(k)) * int(Nexp / k)\n",
    "    random.shuffle(grp)\n",
    "    temp['grp'] = grp\n",
    "    return temp\n",
    "\n",
    "no_strat_assgnt(hist_data_df, 2000, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175000 entries, 0 to 174999\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype   \n",
      "---  ------      --------------   -----   \n",
      " 0   ID          175000 non-null  object  \n",
      " 1   period      175000 non-null  int64   \n",
      " 2   month       175000 non-null  int64   \n",
      " 3   sq_ft       175000 non-null  float64 \n",
      " 4   tier        175000 non-null  category\n",
      " 5   avg_review  175000 non-null  float64 \n",
      " 6   BPday       175000 non-null  float64 \n",
      "dtypes: category(1), float64(3), int64(2), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "hist_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[821.67548629,   9.39342726,  45.93411704,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [977.68632137,  10.        ,  47.02031206,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [772.24643725,   5.05391337,  36.03493243,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       ...,\n",
       "       [931.23973925,   7.82448952,  42.00859311,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [792.20446113,   4.60368051,  32.83121812,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [859.06503328,   7.91434225,  42.09540755,   0.        ,\n",
       "          0.        ,   1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strat_prep_fun(df):\n",
    "    temp = df.copy()\n",
    "\n",
    "    temp = temp.groupby(['ID','tier'], observed=False).agg(\n",
    "        sq_ft = ('sq_ft','mean'),\n",
    "        avg_review = ('avg_review','mean'),\n",
    "        BPday = ('BPday','mean')\n",
    "    )\n",
    "    temp = temp.dropna().reset_index()\n",
    "\n",
    "    num_df = temp.copy().select_dtypes('float64')\n",
    "    cat_df = temp.copy().select_dtypes('category')\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(num_df)\n",
    "    num_np = scaler.transform(num_df)\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(cat_df)\n",
    "    cat_np = enc.transform(cat_df).toarray()\n",
    "\n",
    "    data_np = np.concatenate((num_df, cat_np), axis=1)\n",
    "    del num_df, num_np, cat_df, enc, scaler\n",
    "    return data_np\n",
    "\n",
    "prepared = strat_prep_fun(hist_data_df)\n",
    "\n",
    "prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_assgnt_fun(dat_df, K):\n",
    "    \n",
    "    #Sampling down to a multiple of our number of groups\n",
    "    remainder = len(dat_df) % K\n",
    "    if remainder != 0:\n",
    "        dat_df = dat_df.sample(len(dat_df) - remainder)\n",
    "      \n",
    "    dat_ID = dat_df.ID.astype(str).tolist() # Extract ID for later join\n",
    "\n",
    "    match_len = K - 1 # Number of matches we want to find\n",
    "    match_idx = match_len - 1 # Accounting for 0-indexing\n",
    "    \n",
    "    data_np = strat_prep_fun(dat_df)\n",
    "    N = len(data_np)\n",
    "    \n",
    "    #Calculate distance matrix\n",
    "    from scipy.spatial import distance_matrix\n",
    "    d_mat = distance_matrix(data_np, data_np)\n",
    "    np.fill_diagonal(d_mat,N+1)\n",
    "    # Set up variables\n",
    "    available = [i for i in range(N)]\n",
    "    available_temp = available.copy()\n",
    "    matches_lst = []\n",
    "    lim = int(N/match_len)\n",
    "    \n",
    "    closest = np.argpartition(d_mat, kth=match_idx,axis=1)\n",
    "    \n",
    "    for n in available:\n",
    "        #print(\"n = \", n)\n",
    "        if len(matches_lst) == lim: break\n",
    "        if n in available_temp:\n",
    "            for match_lim in range(match_idx,N-1):\n",
    "                #print(\"match_lim = \", match_lim)\n",
    "                possible_matches = closest[n,:match_lim].tolist()\n",
    "                matches = list(set(available_temp) & set(possible_matches))\n",
    "                #print(\"len(matches) = \",  len(matches))\n",
    "                if len(matches) == match_len:\n",
    "                    matches.append(n)\n",
    "                    matches_lst.append(matches)\n",
    "                    available_temp = [m for m in available_temp if m not in matches]\n",
    "                    break\n",
    "                else:\n",
    "                    closest[n,:] = np.argpartition(d_mat[n,:], kth=match_lim)\n",
    "                    \n",
    "    #Assigning experimental groups to the matched sets\n",
    "    exp_grps = np.array(list(range(K))*(int(N/K))).reshape((int(N/K),K))\n",
    "    exp_grps = exp_grps.tolist()\n",
    "    for j in exp_grps: \n",
    "        np.random.shuffle(j)\n",
    "    #flattening the two lists\n",
    "    import itertools\n",
    "    exp_grps = list(itertools.chain(*exp_grps))\n",
    "    matches_lst2 = list(itertools.chain(*matches_lst))\n",
    "    exp_grps2 = [x for _,x in sorted(zip(matches_lst2,exp_grps))]\n",
    "    \n",
    "    assgnt_df = pd.DataFrame(exp_grps2, columns=['grp'])\n",
    "    assgnt_df.grp = assgnt_df.grp.astype(str)\n",
    "    assgnt_df.grp.loc[assgnt_df.grp == '0'] = 'ctrl'\n",
    "    assgnt_df.grp.loc[assgnt_df.grp == '1'] = 'treat1'\n",
    "    assgnt_df.grp.loc[assgnt_df.grp == '2'] = 'treat2'\n",
    "    \n",
    "    \n",
    "    assgnt_df['ID'] = dat_ID\n",
    "    dat_df = dat_df.merge(assgnt_df, on='ID', how='inner')\n",
    "    return dat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric function for minimum-duration\n",
    "def treat2_metric_fun(df):\n",
    "    model = ols(\"BPday~sq_ft+tier+avg_review+grp\", data=df)\n",
    "    res = model.fit(disp=0)\n",
    "    coeff = res.params['grp[T.treat2]']\n",
    "    return coeff\n",
    "\n",
    "# determining the bootstrap sample CI \n",
    "def boot_CI_fun(df, metric_fun, B=100, conf_level = 0.9):\n",
    "    # set sample size\n",
    "    N = len(df)\n",
    "    coeffs = []\n",
    "\n",
    "    for i in range(B):\n",
    "        sim_df =  df.sample(n=N, replace=True)\n",
    "        coeff = metric_fun(sim_df)\n",
    "        coeffs.append(coeff)\n",
    "    \n",
    "    coeffs.sort()\n",
    "    start_idx = round(B * (1 -conf_level) / 2)\n",
    "    end_idx = - round(B * (1 - conf_level) / 2)\n",
    "    confint = [coeffs[start_idx], coeffs[end_idx]]\n",
    "    return confint\n",
    "\n",
    "# decision function\n",
    "def decision_fun(df, metric_fun, B = 100, conf_level = 0.9):\n",
    "    boot_CI = boot_CI_fun(df, metric_fun, B = B, conf_level=conf_level)\n",
    "    decision = 1 if boot_CI[0] > 0 else 0\n",
    "    return decision\n",
    "\n",
    "def single_sim_fun(df, metric_fun, Nexp, eff_size, B = 100, conf_level = 0.9):\n",
    "\n",
    "    # filter data to a ranodm month\n",
    "    per = random.sample(range(35), 1)[0] + 1\n",
    "    df = df.loc[df.period == per]\n",
    "    df = df.sample(n=Nexp)\n",
    "\n",
    "    # prepare stratified assignemnt for a random sample of desired size\n",
    "    sample_df = df.sample(Nexp)\n",
    "    sim_df = stratified_assgnt_fun(sample_df, K = 3)\n",
    "\n",
    "    # add target effect size\n",
    "    sim_df.BPday = np.where(\n",
    "        sim_df.grp == 'treat2',\n",
    "        sim_df.BPday + eff_size, \n",
    "        sim_df.BPday\n",
    "    )\n",
    "\n",
    "    # calculate decision (should be 1 for true effect)\n",
    "    decision = decision_fun(\n",
    "        sim_df,\n",
    "        metric_fun, \n",
    "        B = B,\n",
    "        conf_level=conf_level\n",
    "        )\n",
    "\n",
    "    return decision\n",
    "\n",
    "def power_sim_fun(df, metric_fun, Nexp, eff_size, Nsim, B = 100, conf_level = 0.9):\n",
    "    power_list = []\n",
    "    for i in range(Nsim):\n",
    "        power_list.append(\n",
    "            single_sim_fun(\n",
    "                df,\n",
    "                metric_fun=metric_fun,\n",
    "                Nexp=Nexp, \n",
    "                eff_size = eff_size,\n",
    "                B = B, \n",
    "                conf_level= conf_level\n",
    "                )\n",
    "            )\n",
    "    power = np.mean(power_list)\n",
    "    return power\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power = power_sim_fun(hist_data_df, treat2_metric_fun, Nexp = 1500, eff_size = 2, \n",
    "                      Nsim = 100, B = 100, conf_level = 0.9)\n",
    "\n",
    "power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>BPday</td>      <th>  R-squared:         </th> <td>   0.047</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.043</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 12 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.68e-13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:52:39</td>     <th>  Log-Likelihood:    </th> <td> -6087.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1500</td>      <th>  AIC:               </th> <td>1.219e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1493</td>      <th>  BIC:               </th> <td>1.223e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>   19.2328</td> <td>    3.574</td> <td>    5.382</td> <td> 0.000</td> <td>   12.223</td> <td>   26.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tier[T.2]</th>     <td>    1.0596</td> <td>    0.841</td> <td>    1.261</td> <td> 0.208</td> <td>   -0.589</td> <td>    2.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tier[T.1]</th>     <td>    5.1705</td> <td>    1.036</td> <td>    4.990</td> <td> 0.000</td> <td>    3.138</td> <td>    7.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grp[T.treat1]</th> <td>    0.9669</td> <td>    0.889</td> <td>    1.088</td> <td> 0.277</td> <td>   -0.776</td> <td>    2.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grp[T.treat2]</th> <td>   -0.1726</td> <td>    0.888</td> <td>   -0.194</td> <td> 0.846</td> <td>   -1.915</td> <td>    1.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sq_ft</th>         <td>    0.0068</td> <td>    0.004</td> <td>    1.838</td> <td> 0.066</td> <td>   -0.000</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_review</th>    <td>    1.6926</td> <td>    0.254</td> <td>    6.675</td> <td> 0.000</td> <td>    1.195</td> <td>    2.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.088</td> <th>  Durbin-Watson:     </th> <td>   1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.048</td> <th>  Jarque-Bera (JB):  </th> <td>   5.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.149</td> <th>  Prob(JB):          </th> <td>  0.0499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.082</td> <th>  Cond. No.          </th> <td>7.95e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.95e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      BPday       & \\textbf{  R-squared:         } &     0.047   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.043   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     12.26   \\\\\n",
       "\\textbf{Date:}             & Tue, 12 Dec 2023 & \\textbf{  Prob (F-statistic):} &  1.68e-13   \\\\\n",
       "\\textbf{Time:}             &     10:52:39     & \\textbf{  Log-Likelihood:    } &   -6087.8   \\\\\n",
       "\\textbf{No. Observations:} &        1500      & \\textbf{  AIC:               } & 1.219e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &        1493      & \\textbf{  BIC:               } & 1.223e+04   \\\\\n",
       "\\textbf{Df Model:}         &           6      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}     &      19.2328  &        3.574     &     5.382  &         0.000        &       12.223    &       26.242     \\\\\n",
       "\\textbf{tier[T.2]}     &       1.0596  &        0.841     &     1.261  &         0.208        &       -0.589    &        2.708     \\\\\n",
       "\\textbf{tier[T.1]}     &       5.1705  &        1.036     &     4.990  &         0.000        &        3.138    &        7.203     \\\\\n",
       "\\textbf{grp[T.treat1]} &       0.9669  &        0.889     &     1.088  &         0.277        &       -0.776    &        2.710     \\\\\n",
       "\\textbf{grp[T.treat2]} &      -0.1726  &        0.888     &    -0.194  &         0.846        &       -1.915    &        1.570     \\\\\n",
       "\\textbf{sq\\_ft}        &       0.0068  &        0.004     &     1.838  &         0.066        &       -0.000    &        0.014     \\\\\n",
       "\\textbf{avg\\_review}   &       1.6926  &        0.254     &     6.675  &         0.000        &        1.195    &        2.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  6.088 & \\textbf{  Durbin-Watson:     } &    1.968  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.048 & \\textbf{  Jarque-Bera (JB):  } &    5.994  \\\\\n",
       "\\textbf{Skew:}          &  0.149 & \\textbf{  Prob(JB):          } &   0.0499  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.082 & \\textbf{  Cond. No.          } & 7.95e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 7.95e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  BPday   R-squared:                       0.047\n",
       "Model:                            OLS   Adj. R-squared:                  0.043\n",
       "Method:                 Least Squares   F-statistic:                     12.26\n",
       "Date:                Tue, 12 Dec 2023   Prob (F-statistic):           1.68e-13\n",
       "Time:                        10:52:39   Log-Likelihood:                -6087.8\n",
       "No. Observations:                1500   AIC:                         1.219e+04\n",
       "Df Residuals:                    1493   BIC:                         1.223e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept        19.2328      3.574      5.382      0.000      12.223      26.242\n",
       "tier[T.2]         1.0596      0.841      1.261      0.208      -0.589       2.708\n",
       "tier[T.1]         5.1705      1.036      4.990      0.000       3.138       7.203\n",
       "grp[T.treat1]     0.9669      0.889      1.088      0.277      -0.776       2.710\n",
       "grp[T.treat2]    -0.1726      0.888     -0.194      0.846      -1.915       1.570\n",
       "sq_ft             0.0068      0.004      1.838      0.066      -0.000       0.014\n",
       "avg_review        1.6926      0.254      6.675      0.000       1.195       2.190\n",
       "==============================================================================\n",
       "Omnibus:                        6.088   Durbin-Watson:                   1.968\n",
       "Prob(Omnibus):                  0.048   Jarque-Bera (JB):                5.994\n",
       "Skew:                           0.149   Prob(JB):                       0.0499\n",
       "Kurtosis:                       3.082   Cond. No.                     7.95e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.95e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data_reg_df = exp_data_df.copy()\n",
    "exp_data_reg_df.BPday = np.where(\n",
    "    (exp_data_reg_df.compliant == 1) & (exp_data_reg_df.grp == 'treat2'),\n",
    "    exp_data_reg_df.BPday -10,\n",
    "    exp_data_reg_df.BPday\n",
    ")\n",
    "\n",
    "ols(\"BPday~sq_ft+tier+avg_review+grp\", data=exp_data_reg_df).fit(disp=0).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compliance_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ctrl</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treat1</th>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treat2</th>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        compliance_rate\n",
       "grp                    \n",
       "ctrl              1.000\n",
       "treat1            0.238\n",
       "treat2            0.166"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data_reg_df.groupby('grp').agg(compliance_rate = ('compliant','mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.041666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_1_coeff = 0.97\n",
    "grp_1_compliance = 0.24\n",
    "\n",
    "CACE_1 = grp_1_coeff / grp_1_compliance\n",
    "CACE_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
